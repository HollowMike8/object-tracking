{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HollowMike8/object-tracking/blob/main/single_object_tracking_mobilenet_ssd_dlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEy9i5RQEx8I"
      },
      "outputs": [],
      "source": [
        "!git\n",
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o_1Mg_-FDUQ",
        "outputId": "150eb835-711f-469b-eb95-708064ae6cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-tracking'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 120 (delta 60), reused 57 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (120/120), 61.53 MiB | 25.82 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HollowMike8/object-tracking.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1wTAwFsNMMqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902ee226-db83-4c7c-80bb-45b75f64a19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4-TPdZjpFJap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b383309e-3376-4592-f23e-03bc2415ed50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/object-tracking\n"
          ]
        }
      ],
      "source": [
        "%cd object-tracking/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "caB1F7pQFSN6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import imutils\n",
        "import datetime\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SXYQlSrdFgqA"
      },
      "outputs": [],
      "source": [
        "path_dir: str = r\"/content/object-tracking\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,path_dir)\n",
        "import single_object_config as soc\n",
        "from centroidtracker import CentroidTracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yOLxxdhZKjRD"
      },
      "outputs": [],
      "source": [
        "# load input video (race.mp4), intitialize the writer, tracker \n",
        "vs = cv2.VideoCapture(os.path.join(soc.input_dir, \"race.mp4\"))\n",
        "\n",
        "tracker = None\n",
        "writer = None\n",
        "\n",
        "# intitialize the CentroidTracker, objects\n",
        "ct = CentroidTracker(maxDisappeared=40, maxDistance=40)\n",
        "objects = None\n",
        "\n",
        "# refresh rate for object detection (object detection every N frames)\n",
        "refresh_rate = 60\n",
        "\n",
        "# initiate totalFrames processed\n",
        "totalFrames = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRDZqfjIAT4E"
      },
      "source": [
        "# **mobilenet_ssd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gC8pGyoJJqUH"
      },
      "outputs": [],
      "source": [
        "# list of all the classes mobilenet_ssd was trained on\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
        "           \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \n",
        "           \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \n",
        "           \"tvmonitor\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ldKIicqqJ9Eh"
      },
      "outputs": [],
      "source": [
        "# load the mobilenet_ssd caffe model\n",
        "prototxt_path = os.path.join(soc.cnn_caffe_dir , \"MobileNetSSD_deploy.prototxt\")\n",
        "model_path = os.path.join(soc.cnn_caffe_dir , \"MobileNetSSD_deploy.caffemodel\")\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFL2Qy0xc_l0"
      },
      "outputs": [],
      "source": [
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# initialize list to capture the bounding box coordinates\n",
        "rects = []\n",
        "\n",
        "# loop over thr frames in the input video\n",
        "while True:\n",
        "  (grab, frame) = vs.read()\n",
        "\n",
        "  # to break out of loop after the end of video\n",
        "  if grab == False:\n",
        "    break\n",
        "\n",
        "  # convert from BGR to RGB for dlib tracker\n",
        "  frame = imutils.resize(frame, width=600)\n",
        "  img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # writing the video\n",
        "  if writer is None:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    writer = cv2.VideoWriter(os.path.join(soc.output_dir, \"race_dlib_mobilenet_ssd.avi\"), \n",
        "                             fourcc, 30, (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "  # object detection (for every N frames)\n",
        "  if totalFrames % refresh_rate == 0:\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (w, h), 127.5)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    # find the index of the detection with the largest confidence (single obj)\n",
        "    if objects == None and len(detections) > 0:\n",
        "      i = np.argmax(detections[0, 0, :, 2])\n",
        "      conf = detections[0, 0, i, 2]\n",
        "      label = CLASSES[int(detections[0, 0, i, 1])]\n",
        "\n",
        "    # find the index of the previouly existing single obj detection\n",
        "    else:\n",
        "      for i in range(0, detections.shape[2]):\n",
        "        conf = detections[0, 0, i, 2]\n",
        "        label = CLASSES[int(detections[0, 0, i, 1])]\n",
        "        # print(\"Label of progressive detection:%s\"% label)\n",
        "\n",
        "        temp = detections[0, 0, i, 3:7]*np.array([w, h, w, h])\n",
        "        (startX, startY, endX, endY) = temp.astype(\"int\")\n",
        "        # print(\"Rect of progressive detection:%s\"% temp)\n",
        "\n",
        "        if label == soc.label:\n",
        "          rects = []\n",
        "          objects_old = objects.copy()\n",
        "          rects.append((startX, startY, endX, endY))\n",
        "          objects = ct.update(rects)\n",
        "\n",
        "          # check the new rect is already detected/tracked single obj\n",
        "          if (objects_old[0] == objects[0]).all():\n",
        "            continue\n",
        "          else:\n",
        "            break\n",
        "\n",
        "        elif label == 'background':\n",
        "          label = soc.label\n",
        "\n",
        "    if conf > soc.thres_confidence and label == soc.label:\n",
        "      # compute the bounding box coordinates\n",
        "      box = detections[0, 0, i, 3:7]*np.array([w, h, w, h])\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "      # construct the dlib correlation tracker using bouding box coordinates\n",
        "      tracker = dlib.correlation_tracker()\n",
        "      rect = dlib.rectangle(startX, startY, endX, endY)\n",
        "      tracker.start_track(img, rect)\n",
        "\n",
        "      # draw the bouding box rectangle and label in the frame\n",
        "      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "      cv2.putText(frame, label, (startX, startY-15), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                  0.45, (0, 255, 0), 2)\n",
        "      \n",
        "      # empty the rect list and update the centroid/centroids\n",
        "      rects = []\n",
        "      rects.append((startX, startY, endX, endY))\n",
        "      objects = ct.update(rects)\n",
        "  \n",
        "  # object tracking     \n",
        "  else:\n",
        "    tracker.update(img)\n",
        "    pos = tracker.get_position()\n",
        "\n",
        "    # unpack the position object\n",
        "    startX = int(pos.left())\n",
        "    startY = int(pos.top())\n",
        "    endX = int(pos.right())\n",
        "    endY = int(pos.bottom())\n",
        "\n",
        "    # draw the bouding box rectangle and label in the frame\n",
        "    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "    cv2.putText(frame, label, (startX, startY-15), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                0.45, (0, 255, 0), 2)\n",
        "    \n",
        "    # empty the rect list and update the centroid/centroids\n",
        "    rects = []\n",
        "    rects.append((startX, startY, endX, endY))\n",
        "    objects = ct.update(rects)\n",
        "\n",
        "  # write the sketched frame     \n",
        "  if writer is not None:\n",
        "    writer.write(frame)\n",
        "\n",
        "  # show the output frame\n",
        "  cv2_imshow(frame)\n",
        "  key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "  # if the `q` key was pressed, break from the loop\n",
        "  if key == ord(\"q\"):\n",
        "    break\n",
        "\n",
        "  # update the totalFrames processed\n",
        "  totalFrames += 1\n",
        "\n",
        "end_time = datetime.datetime.now()\n",
        "elapsed_time = (end_time-start_time).total_seconds()\n",
        "print(\"Elapsed time: {:.2f}\".format(elapsed_time))\n",
        "print(\"Approx. FPS: {:.2f}\".format(totalFrames/elapsed_time))\n",
        "\n",
        "# check to see if we need to release the video writer pointer\n",
        "if writer is not None:\n",
        "  writer.release()\n",
        "\n",
        "# do a bit of cleanup\n",
        "cv2.destroyAllWindows()\n",
        "vs.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hanlag-dOzz"
      },
      "source": [
        "# **Notes**\n",
        "1. Object detection is performed once in every 60 frames\n",
        "\n",
        "2. Object detections (except initial) use additional criteria of checking if  the new detection is close to previous bounding box (from tracking)\n",
        "\n",
        "3. mobilenet_ssd fails in some detection steps (for refresh_rate = 30 frames) due to occlusion\n",
        "\n",
        "4. Unsuccessful detection steps are skipped and tracking is used as before\n",
        "  1. Tracking is re-initiated but with the last successful bounding box "
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "single_object_tracking_mobilenet_ssd_dlib.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6eAQeBIKa4fG1Pgf1bzxr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
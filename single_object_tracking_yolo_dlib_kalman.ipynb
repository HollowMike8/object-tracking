{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single_object_tracking_yolo_dlib_kalman.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-Y65gysDNcqq"
      ],
      "authorship_tag": "ABX9TyO6wZHJ+Sa9F7APJF7s9qYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HollowMike8/object-tracking/blob/main/single_object_tracking_yolo_dlib_kalman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6h6s6Dgykvd"
      },
      "outputs": [],
      "source": [
        "!git\n",
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HollowMike8/object-tracking.git"
      ],
      "metadata": {
        "id": "dxUCgaE9yu9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a31d17-2581-4a6b-bbe6-f672425009f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-tracking'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 129 (delta 66), reused 54 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (129/129), 61.53 MiB | 36.36 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade imutils\n",
        "!pip install filterpy"
      ],
      "metadata": {
        "id": "5tLTlo4FyxFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd object-tracking/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mUoNBkWyym4",
        "outputId": "5e550ad8-d177-49b3-f5a4-32c1c86f5494"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/object-tracking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import datetime\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "FCATtKfCy0RD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir: str = r\"/content/object-tracking\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,path_dir)\n",
        "import single_object_config as soc\n",
        "from centroidtracker import CentroidTracker\n",
        "from correlation_tracker import CorrelationTracker\n",
        "from first_order_kalman_tracker import KalmanBoxTracker"
      ],
      "metadata": {
        "id": "zZlZ-a5Dy2DQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load input video (race.mp4), intitialize the writer, tracker \n",
        "vs = cv2.VideoCapture(os.path.join(soc.input_dir, \"race.mp4\"))\n",
        "\n",
        "tracker = None\n",
        "writer = None\n",
        "\n",
        "# intitialize the CentroidTracker, objects\n",
        "ct = CentroidTracker(maxDisappeared=40, maxDistance=30)\n",
        "objects = None\n",
        "\n",
        "# refresh rate for object detection (object detection every N frames)\n",
        "refresh_rate = 60\n",
        "\n",
        "# initiate totalFrames processed\n",
        "totalFrames = 0\n",
        "\n",
        "# initialize the dictionaries to capture detections and trackings\n",
        "dets_dict = {}\n",
        "trks_dict = {}"
      ],
      "metadata": {
        "id": "MrrGx-8Dz0aD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Import yolo model and class labels**"
      ],
      "metadata": {
        "id": "-Y65gysDNcqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the files if required\n",
        "\n",
        "# change the dir to location where downloads save\n",
        "%cd /content/object-tracking/yolo-coco/\n",
        "\n",
        "!wget \"https://pjreddie.com/media/files/yolov3.weights\"\n",
        "\n",
        "!wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\"\n",
        "\n",
        "# !wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\"\n",
        "\n",
        "#change the dir back to root dir\n",
        "%cd /content/object-tracking/"
      ],
      "metadata": {
        "id": "jSD1zcwKz5FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the COCO class labels for YOLO model\n",
        "labels_path = os.path.join(path_dir, \"yolo-coco\", \"coco.names\")\n",
        "labels = open(labels_path, \"r\").read().strip().split(\"\\n\")\n",
        "\n",
        "# assign random colours to all COCO class labels\n",
        "np.random.seed(42)\n",
        "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype = \"uint8\")"
      ],
      "metadata": {
        "id": "3LBBDWxDz57P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the yolov3 model\n",
        "weightsPath = os.path.join(path_dir, \"yolo-coco\", \"yolov3.weights\")\n",
        "configPath = os.path.join(path_dir, \"yolo-coco\", \"yolov3.cfg\")\n",
        "\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
      ],
      "metadata": {
        "id": "RIn26SQ3z8wQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **main**"
      ],
      "metadata": {
        "id": "eH85DGG6NkK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize list to capture the bounding box coordinates\n",
        "rects = []\n",
        "\n",
        "# loop over thr frames in the input video\n",
        "while True:\n",
        "  (grab, frame) = vs.read()\n",
        "\n",
        "  # to break out of loop at the end of video\n",
        "  if grab == False:\n",
        "    break\n",
        "  \n",
        "  # convert from BGR to RGB and resize\n",
        "  frame = imutils.resize(frame, width=600)\n",
        "  img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # writing the video\n",
        "  if writer is None:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    writer = cv2.VideoWriter(os.path.join(soc.output_dir, \"race_yolo_dlib_kalman.avi\"), \n",
        "                             fourcc, 30, (frame.shape[1], frame.shape[0]), True)\n",
        "  \n",
        "  # object detection (for every N frames)\n",
        "  # initialize lists to append the bounding boxes, confidences and class IDs\n",
        "  boxes = []\n",
        "  confidences = []\n",
        "  classIDs = []\n",
        "\n",
        "  if totalFrames % refresh_rate == 0:\n",
        "    (h,w) = frame.shape[:2]\n",
        "\n",
        "    # determine only *output* layer names we need from yolo (3 output layers)\n",
        "    layer_names = net.getLayerNames()\n",
        "    layer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    # construct a blob from the input image and then perform a forward pass\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, \n",
        "                                 crop=False)\n",
        "    net.setInput(blob)\n",
        "    layerOutputs = net.forward(layer_names)\n",
        "\n",
        "    # loop over each layer of the outputs (3)\n",
        "    for output in layerOutputs:\n",
        "      # loop over the detections in each output\n",
        "      for detection in output:\n",
        "        scores = detection[5:]\n",
        "        classID = np.argmax(scores)\n",
        "        confidence = scores[classID]\n",
        "\n",
        "        # consider only predictions with confidence > threshold\n",
        "        if confidence > soc.yolo_thres_confidence:\n",
        "          # scale the bounding box parameters\n",
        "          box = detection[0:4] * np.array([w, h, w, h])\n",
        "          (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "          # find the corner points for cv2.rectangle\n",
        "          startX = int(centerX - (width/2))\n",
        "          startY = int(centerY - (height/2))\n",
        "          endX = int(centerX + (width/2))\n",
        "          endY = int(centerY + (height/2))\n",
        "\n",
        "          boxes.append([startX, startY, endX, endY])\n",
        "          confidences.append(float(confidence))\n",
        "          classIDs.append(classID)\n",
        "    \n",
        "    # apply non-max supression with threshold IoU= 0.3 and \n",
        "    # threshold confidence=soc.yolo_thres_confidence\n",
        "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, soc.yolo_thres_confidence, 0.3)\n",
        "\n",
        "    # capture the all detections with class labels \"person\"\n",
        "    if len(idxs) > 0:\n",
        "      person_list = {confidences[i]:boxes[i] for i in idxs.flatten() \n",
        "                    if labels[classIDs[i]]==soc.label}\n",
        "    \n",
        "    # find the fisrt time detection with the largest confidence (single obj)\n",
        "    if objects == None and bool(person_list):\n",
        "      label = soc.label\n",
        "      max_conf = max(person_list.keys())\n",
        "      (startX, startY, endX, endY) = person_list[max_conf]\n",
        "    \n",
        "    # find the index of the previouly existing single obj detection\n",
        "    elif objects != None and bool(person_list):\n",
        "      label = soc.label\n",
        "      rects_old = rects\n",
        "\n",
        "      for key in person_list.keys():\n",
        "        conf = key\n",
        "        (startX, startY, endX, endY) = person_list[conf]\n",
        "\n",
        "        rects = []\n",
        "        objects_old = objects.copy()\n",
        "        rects.append((startX, startY, endX, endY))\n",
        "        objects = ct.update(rects)\n",
        "\n",
        "        # check the new rect is already detected/tracked single obj\n",
        "        if (objects_old[0] == objects[0]).all():\n",
        "          (startX, startY, endX, endY) = rects_old[0]\n",
        "          continue\n",
        "        else:\n",
        "          break\n",
        "    \n",
        "    # capture the detections in the dictionary\n",
        "    bbox = [startX, startY, endX, endY]\n",
        "    dets_dict[totalFrames] = bbox\n",
        "\n",
        "    # construct the dlib correlation tracker using bounding box coordinates\n",
        "    if totalFrames==0:\n",
        "      tracker_1 = CorrelationTracker(bbox, img)\n",
        "    else:\n",
        "      tracker_1.update(bbox, img)\n",
        "\n",
        "    # construct the kalman tracker using bounding box coordinates\n",
        "    if totalFrames==0:\n",
        "      tracker_2 = KalmanBoxTracker(bbox=bbox)\n",
        "\n",
        "    # draw the bounding box rectangle and label in the frame\n",
        "    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "    cv2.putText(frame, label, (int((startX + endX)/2), int((startY + endY)/2)), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "\n",
        "    # write the detection step in the frame\n",
        "    cv2.putText(frame, \"DETECTION\", (420, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
        "                (0, 0, 255), 2)\n",
        "\n",
        "    # empty the rect list and update the centroid/centroids\n",
        "    rects = []\n",
        "    rects.append((startX, startY, endX, endY))\n",
        "    objects = ct.update(rects)\n",
        "\n",
        "  # object tracking\n",
        "  else:\n",
        "    # predict using dlib correlation tracker\n",
        "    (startX, startY, endX, endY) = tracker_1.predict(img)\n",
        "\n",
        "    bbox_dlib = [startX, startY, endX, endY]\n",
        "\n",
        "    # predict and update using kalman tracker\n",
        "    trks = tracker_2.predict(img)\n",
        "    pos_2 = [int(coor) for coor in trks]\n",
        "\n",
        "    # capture the kalman tracking in the dictionary\n",
        "    trks_dict[totalFrames] = pos_2\n",
        "\n",
        "    if totalFrames % 5 == 0:\n",
        "      # update/correct kalman prediction using bounding box from dlib tracker\n",
        "      tracker_2.update(bbox_dlib, img)\n",
        "\n",
        "    # find the distance between bounding box centers from dlib and kalman\n",
        "    center_d = np.array([(startX + endX)/2, (startY + endY)/2])\n",
        "    center_k = np.array([(pos_2[0] + pos_2[2])/2, (pos_2[1] + pos_2[3])/2])\n",
        "    dist = np.linalg.norm(center_d-center_k)\n",
        "    # print(\"dist: %s\"% dist)\n",
        "\n",
        "    # draw bounding box rectangle (for correlation tracker)\n",
        "    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 255), 2)\n",
        "    cv2.putText(frame, \"dlib\", (startX, startY-15), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                0.45, (0, 255, 255), 2)\n",
        "       \n",
        "    # draw bounding box rectangle (for kalman tracker)\n",
        "    cv2.rectangle(frame,(pos_2[0],pos_2[1]),(pos_2[2],pos_2[3]), (0, 0, 255), 2)\n",
        "    cv2.putText(frame,\"kalman\",(pos_2[0], pos_2[3]+15),cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                0.45, (0, 0, 255), 2)  \n",
        "     \n",
        "    # write the tracking step and label in the frame\n",
        "    cv2.putText(frame, label, (int((startX + endX)/2), int((startY + endY)/2)), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, \"TRACKING\", (420, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
        "                (0, 0, 255), 2)\n",
        "\n",
        "    # empty the rect list and update the centroid/centroids\n",
        "    rects = []\n",
        "    if dist > 40 and 0.8 < (np.divide(center_k, center_d)).all() < 1.2:\n",
        "      (startX, startY, endX, endY) = pos_2\n",
        "    rects.append((startX, startY, endX, endY))\n",
        "    objects = ct.update(rects)\n",
        "\n",
        "  # write the sketched frame     \n",
        "  if writer is not None:\n",
        "    writer.write(frame)\n",
        "\n",
        "  # show the output frame\n",
        "  cv2_imshow(frame)\n",
        "  key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "  # if the `q` key was pressed, break from the loop\n",
        "  if key == ord(\"q\"):\n",
        "    break\n",
        "\n",
        "  # update the totalFrames processed\n",
        "  totalFrames += 1\n",
        "\n",
        "# check to see if we need to release the video writer pointer\n",
        "if writer is not None:\n",
        "  writer.release()\n",
        "\n",
        "# do a bit of cleanup\n",
        "cv2.destroyAllWindows()\n",
        "vs.release()"
      ],
      "metadata": {
        "id": "S1YuIlLz2b9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}